---
title: "eda project"
author: "22MIA1048"
date: "`r Sys.Date()`"
output: html_document
---

```{r}
file_path <- "C:/Users/indum/Downloads/teslaa.csv"
df<- read.csv(file_path)
df
```




```{r}
library(quantmod)
library(caret)
```


```{r}
# Fetch Tesla stock data
getSymbols("TSLA", from = "2020-01-01", to = Sys.Date())


```


```{r}
# Prepare data
tesla_data <- TSLA[, "TSLA.Adjusted"]
colnames(tesla_data) <- c("Close")
tesla_data <- na.omit(tesla_data)
tesla_data
```
```{r}
# Feature engineering
tesla_data$lag1 <- Lag(tesla_data$Close, 1) 
tesla_data$lag2 <- Lag(tesla_data$Close, 2)
tesla_data$lag3 <- Lag(tesla_data$Close, 3)
tesla_data <- na.omit(tesla_data)
tesla_data
```


```{r}
# Split data into training and testing sets
train_size <- floor(0.8 * nrow(tesla_data))
train <- tesla_data[1:train_size, ]
test <- tesla_data[(train_size + 1):nrow(tesla_data), ]
test
```


```{r}
# Train the model (linear regression)
model <- train(Close ~ lag1 + lag2 + lag3, data = train, method = "lm")
model
```


```{r}

# Make predictions
predictions <- predict(model, newdata = test)
predictions
```


```{r}
mse <- mean((test$Close - predictions)^2)
print(paste("Mean Squared Error:", mse))
```


```{r}
# Plot the closing prices over time
library(ggplot2)
ggplot(tesla_data, aes(x = index(tesla_data), y = Close)) +
  geom_line() +
  labs(x = "Date", y = "Closing Price", title = "Tesla Closing Prices Over Time")
labs
```


```{r}


```


```{r}
#Tesla stock price predicution
library(ggplot2)
library(quantmod)
getSymbols("TSLA", from = "2020-01-01", to = Sys.Date())
tesla_data <- TSLA[, "TSLA.Adjusted"]
colnames(tesla_data) <- c("Close")
tesla_data <- na.omit(tesla_data)
tesla_data$lag1 <- lag(tesla_data$Close, 1) # Previous day's closing price
tesla_data$lag2 <- lag(tesla_data$Close, 2) # Closing price two days ago
tesla_data$lag3 <- lag(tesla_data$Close, 3) # Closing price three days ago
tesla_data <- na.omit(tesla_data)
model <- lm(Close ~ lag1 + lag2 + lag3, data = tesla_data)
predictions_present <- predict(model, newdata = tesla_data)
future_data <- tail(tesla_data, 1) 
future_data$lag1 <- tail(tesla_data$Close, 1) 
future_data$lag2 <- lag(future_data$lag1, 1) 
predictions_future <- predict(model, newdata = future_data)
plot_data <- data.frame(Date = index(tesla_data), Close = tesla_data$Close, 
                        Prediction_Present = predictions_present, Prediction_Future = predictions_future)
ggplot(plot_data, aes(x = Date)) +
  geom_line(aes(y = Close, color = "Actual")) +
  geom_line(aes(y = Prediction_Present, color = "Prediction Present")) +
  geom_line(aes(y = Prediction_Future, color = "Prediction Future")) +
  labs(x = "Date", y = "Closing Price", title = "Tesla Stock Price Prediction") +
  scale_color_manual(values = c("Actual" = "red", "Prediction Present" = "blue", "Prediction Future" = "orange")) +
  theme_minimal()

```


```{r}
#growth predicition
tesla_data <- TSLA[, "TSLA.Adjusted"]
colnames(tesla_data) <- c("Close")
tesla_data$Daily_Return <- dailyReturn(tesla_data$Close, type = "log")
ggplot(data = tesla_data, aes(x = index(tesla_data), y = Daily_Return)) +
  geom_line() +
  labs(x = "Date", y = "Daily Percentage Change", title = "Tesla Stock Growth Visualization") +
  theme_minimal()

```


```{r}
# Time Series
library(readr)
library(ggplot2)
data <- read_csv("C:/Users/indum/Downloads/teslaa.csv")
ggplot(data, aes(x = Open, y = Close)) +
  geom_line() +
  labs(x = "Timestamp", y = "Value", title = "Time Series Plot")




```


```{r}
# Parito chart
library(readr)
library(ggplot2)
data <- read_csv("C:/Users/indum/Downloads/teslaa.csv")
defect_counts <- table(data$Open)
defect_freq <- sort(defect_counts, decreasing = TRUE)
defect_names <- names(defect_freq)
cumulative_percentage <- cumsum(defect_freq) / sum(defect_freq) * 100
pareto_data <- data.frame(
  Defect_Type = factor(defect_names, levels = defect_names),
  Frequency = defect_freq,
  Cumulative_Percentage = cumulative_percentage
)
ggplot(pareto_data, aes(x = reorder(Defect_Type, defect_freq), y = cumulative_percentage)) +
  geom_bar(stat = "identity", fill = "blue") +
  geom_line(color = "red", group = 1) +
  geom_point(color = "red", size = 3) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Defect Type", y = "Cumulative Percentage", title = "Pareto Chart of Defect Types")




```
```{r}
#chi-square test
library(readr)
data <- read_csv("C:/Users/indum/Downloads/teslaa.csv")
contingency_table <- table(data$High, data$Low)
chi_sq_result <- chisq.test(contingency_table)
print(chi_sq_result)

```
```{r}
# Back ward elimination
library(readr)
data <- read.csv("C:/Users/indum/Downloads/teslaa.csv")
full_model <- lm(Close ~ ., data = data)
while (TRUE) {
  p_values <- summary(full_model)$coefficients[, "Pr(>|t|)"][-1]  # Exclude intercept
  max_p_value <- max(p_values, na.rm = TRUE)
  
  if (!is.na(max_p_value) && max_p_value > 0.05) {  # Check if any p-value is above significance level (e.g., 0.05)
    var_to_remove <- names(which(p_values == max_p_value))
    formula <- as.formula(paste("dependent_var ~ .", collapse = " - ", 
                                ignore.exprs = var_to_remove))
    full_model <- lm(formula, data = data)
  } else {
    break
  }
}

# Step 3: Print the final model summary
summary(full_model)

```

```{r}
#Scatterplot
library(readr)
data <- read.csv("C:/Users/indum/Downloads/teslaa.csv")
variable1 <- data$High
variable2 <- data$Low
plot(variable1, variable2,xlab = "High", ylab = "Low", main = "Scatter Plot of High vs Low")
```


```{r}
# Forward Selection
library(readr)
data <- read.csv("C:/Users/indum/Downloads/teslaa.csv")

selected_predictors <- c(data$Close)
while (length(selected_predictors) < ncol(data) - 1) {  # Exclude the dependent variable
  remaining_predictors <- setdiff(names(data), selected_predictors)
  best_p_value <- Inf
  best_predictor <- NULL
  
  for (predictor in remaining_predictors) {
    model_formula <- as.formula(paste("dependent_var ~", paste(c(selected_predictors, predictor), collapse = " + ")))
    temp_model <- lm(model_formula, data = data)
    p_value <- summary(temp_model)$coefficients[which(rownames(summary(temp_model)$coefficients) == predictor), "Pr(>|t|)"]
    
    if (p_value < best_p_value) {
      best_p_value <- p_value
      best_predictor <- predictor
    }
  }
  
  selected_predictors <- c(selected_predictors, best_predictor)
}
final_model_formula <- as.formula(paste("dependent_var ~", paste(selected_predictors, collapse = " + ")))
summary(final_model_formula)

```

```{r}
```


```{r}

```


```{r}
# Pearson correlation coefficient
library(readr)
data <- read.csv("C:/Users/indum/Downloads/teslaa.csv")
correlation <- cor(data$Open, data$Close, method = "pearson")
correlation
```




```{r}
#k means clustring algorithm
library(readr)
str(data)
selected_data <- data[, c("High", "Open", "Close")]
k <- 3
kmeans_result <- kmeans(selected_data, centers = k)
print(kmeans_result$centers)
cluster_labels <- kmeans_result$cluster
data_with_clusters <- cbind(data, "Cluster" = cluster_labels)

```



```{r}
